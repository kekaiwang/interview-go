# Index

## 什么是索引 index ？

数据库中的索引，就好比一本书的目录，它可以帮我们快速进行特定值的定位与查找，从而加快数据查询的效率。  
索引就是帮助数据库管理系统高效获取数据的数据结构。

在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。

## 索引的常见模型（数据结构）

1. **哈希表**是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。

    不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。拉链法

    ![image](https://mail.wangkekai.cn/1629296492400.jpg)

    User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。  
    需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。

    > 哈希表这种结构适用于只有等值查询的场景  
    > 有序数组索引只适用于静态存储引擎

2. **二叉搜索树**，每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -> UserC -> UserF -> User2 这个路径得到。这个时间复杂度是 O(log(N))。

3. **“N 叉”树**，N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。

### InnoDB 的索引模型

![image](https://mail.wangkekai.cn/6C4E0023-4F89-4E02-BC8B-F4E17709BC4A.png)
**图1**

- **主键索引**的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为*聚簇索引*（clustered index）。

- **非主键索引**的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为*二级索引*（secondary index）。

**基于主键索引和普通索引的查询有什么区别？**

1. 如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；
1. 如果语句是 `select * from T where k=5`，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为**回表**。

### 索引维护

B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为**页分裂**。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。

> 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。

**主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**。

插入一个问题：如果我执行 `select * from T where k between 3 and 5`，需要执行几次树的搜索操作，会扫描多少行？

1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；
2. 再到 ID 索引树查到 ID=300 对应的 R3；
3. 在 k 索引树取下一个值 k=5，取得 ID=500；
4. 再回到 ID 索引树查到 ID=500 对应的 R4；
5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。

### 覆盖索引

索引 X 已经“覆盖了”我们的查询需求，我们称为**覆盖索引**。  
由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

### 最左前缀原则

![image](https://mail.wangkekai.cn/07DE4FF9-520B-4BD4-B12D-78344AB251CF.png)

**B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。**

*索引项是按照索引定义里面出现的字段顺序排序的*.

不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。

**第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的**。

B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。

### 索引下推

MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，**对索引中包含的字段先做判断**，直接过滤掉不满足条件的记录，减少回表次数。

### 重建索引

重建普通索引可以节省空间。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。
 `alter table T engine=InnoDB`

## 普通索引和唯一索引应该怎么选择？

使用上图1，假设，执行查询的语句是 `select id from T where k=5`

### 查询过程

这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。

- **对于普通索引来说**，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- **对于唯一索引来说**，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

> 在 InnoDB 中，每个数据页的大小默认是 16KB。当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。

因为引擎是按页读写的，所以说，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。  
当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。  
对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。

### 更新过程

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 `change buffer` 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 `change buffer` 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

*虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上*。

> 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。**除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge**。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

**merge 的执行流程：**

1. 从磁盘读入数据页到内存（老版本的数据页）
2. 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；
3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。

**什么条件下可以使用 change buffer 呢？**

对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

**唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用**。
> change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

**如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的**?

1. 第一种情况是，**这个记录要更新的目标页在内存中**。这时，InnoDB 的处理流程如下：

    - *对于唯一索引来说*，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
    - *对于普通索引来说*，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

    > 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

2. 第二种情况是，**这个记录要更新的目标页不在内存中**。这时，InnoDB 的处理流程如下：

    - *对于唯一索引来说*，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
    - *对于普通索引来说*，则是将更新记录在 change buffer，语句执行就结束了。

> 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

### change buffer 的使用场景

**普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？**

因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

> 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，**假设一个业务的更新模式是写入之后马上会做查询**，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。**所以，对于这种业务模式来说，change buffer 反而起到了副作用。**

### 索引选择和实践

普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。**所以，我建议你尽量选择普通索引。**

> 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

在实际使用中，你会发现，*普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的*。

### change buffer 和 redo log

**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**

![image](https://mail.wangkekai.cn/changebuffer1602757949575.jpg)

执行这条插入操作

```mysql
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
```

分析这条更新语句，你会发现它涉及了四个部分：`内存`、`redo log（ib_log_fileX）`、 `数据表空间（t.ibd）`、`系统表空间（ibdata1）`。

这条更新语句做了如下的操作（按照图中的数字顺序）：

1. Page 1 在内存中，直接更新内存；
1. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息
1. 将上述两个动作记入 redo log 中（图中 3 和 4）。

那在这之后的读请求，要怎么处理呢？

比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。
![image](https://mail.wangkekai.cn/changebufferselect1602758426849.jpg)

1. 读 Page 1 的时候，直接从内存返回。WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。
1. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗**。

## MySQL为什么有时候会选错索引？

### 优化器的逻辑

> **“区分度”**:一个索引上不同的值越多，这个索引的区分度就越好。  
> **“基数”（cardinality）**:一个索引上不同的值的个数。也就是说，这个基数越大，索引的区分度越好。

可以使用 `show index from t` 方法，看到一个索引的基数。

**MySQL 是怎样得到索引的基数的呢？ 采样统计方法**.

采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。
而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 `innodb_stats_persistent` 的值来选择：

- 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
- 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。

```mysql
analyze table [NAME] 命令，可以用来重新统计索引信息。
如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，也就是索引统计不准确时，可以采用这个方法来处理。
```

> explain 执行的时候，如果查询使用的是普通索引，都要再回到主键上查出整行数据，这个代价优化器也要计算在内。

### 索引选择异常和处理

- **一种方法是，像我们第一个例子一样，采用 force index 强行选择一个索引。**

> 很多时候我们不喜欢使用 force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改；其实使用 force index 最主要的问题还是变更的及时性。

- **第二种方法就是，我们可以考虑修改语句，引导 MySQL 使用我们期望的索引。**  
    比如 `order by b,a limit 1`
- **第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。**

## 怎么给字符串加索引？

**使用非前缀索引进行查询的执行顺序：**

1. 从索引树 index1 找到满足索引值的这条记录，取得字段的值；
2. 到主键上查到主键值是 ID2 的行，判断字段的值是正确的，将这行记录加入结果集；
3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足查询的条件了，循环结束。

**使用前缀索引进行查询的执行顺序：**

1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；
2. 到主键上查到主键值是 ID1 的行，判断出 email 的值不是’zhangssxyz@xxx.com’，这行记录丢弃；
3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；
4. 重复上一步，直到在 index2 上取到的值不是’zhangs’时，循环结束。

> 通过这个对比可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。但是如果定义的字节多几个，可能就只需要扫描一行了。

**使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**

### 前缀索引对覆盖索引的影响

使用前缀索引即使长度足够长， InnoDB 还是要回到主键索引再去查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。  
**使用前缀索引就用不上覆盖索引对查询性能的优化了**，这也是你在选择是否使用前缀索引时需要考虑的一个因素。

### 其他方式

- **第一种方式是使用倒序存储**。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写

```mysql
mysql> select field_list from t where id_card = reverse('input_id_card_string');
```

- **第二种方式是使用 hash 字段**。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。 每次插入时 crc32() 得到新字段。

**使用倒序存储和使用 hash 字段这两种方法的异同点。**

首先，它们的相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。

**它们的区别，主要体现在以下三个方面：**

1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。
2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。
3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

我们来回顾一下，你可以使用的方式有：

1. 直接创建完整索引，这样可能比较占用空间；
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

## 都说InnoDB好，那还要不要使用Memory引擎？

两个 group by 语句都用了 order by null，为什么使用内存临时表得到的语句结果里，0 这个值在最后一行；而使用磁盘临时表得到的结果里，0 这个值在第一行？

### 内存表的数据组织结构

```mysql
create table t1(id int primary key, c int) engine=Memory;
create table t2(id int primary key, c int) engine=innodb;
insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
```

分别执行 `select * from t1 和 select * from t2`。

![image](https://mail.wangkekai.cn/05973FF5-DA5A-46A3-98EC-C5620780A70C.png)

可以看到，内存表 t1 的返回结果里面 0 在最后一行，而 InnoDB 表 t2 的返回结果里 0 在第一行。**要从这两个引擎的主键索引的组织方式说起。**

表 t2 用的是 InnoDB 引擎，它的主键索引 id 的组织方式，你已经很熟悉了：InnoDB 表的数据就放在主键索引树上，主键索引是 B+ 树。所以表 t2 的数据组织方式如下图所示：

![image](https://mail.wangkekai.cn/0E9B12CD-356E-4E0B-98C4-FD511E17C72B.png)

主键索引上的值是有序存储的。在执行 select * 的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0 就出现在第一行。

与 InnoDB 引擎不同，Memory 引擎的数据和索引是分开的。

![image](https://mail.wangkekai.cn/D642AFB6-0183-47A8-998C-8D61AA58D54C.png)

内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。

在内存表 t1 中，当我执行 select * 的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0 就是最后一个被读到，并放入结果集的数据。

InnoDB 和 Memory 引擎的数据组织方式是不同的：

- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为**索引组织表**（Index Organizied Table）。
- 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为**堆组织表**（Heap Organizied Table）。

这两个引擎的一些典型不同：

1. InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
2. 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
3. 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
4. InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
5. InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。

由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。比如，如果要在表 t1 中执行：

```mysql
delete from t1 where id=5;
insert into t1 values(10,10);
select * from t1;
```

就会看到返回结果里，id=10 这一行出现在 id=4 之后，也就是原来 id=5 这行数据的位置。

需要指出的是，表 t1 的这个主键索引是哈希索引，因此如果执行范围查询，比如

```mysql
select * from t1 where id<5;
```

### hash 索引和 B-Tree 索引

内存表也是支 B-Tree 索引的。在 id 列上创建一个 B-Tree 索引，SQL 语句可以这么写：

```mysql
alter table t1 add index a_btree_index using btree (id);
```

这时，表 t1 的数据组织形式就变成了这样：

![image](https://mail.wangkekai.cn/7A19C9FC-C683-4FE5-938A-191AD2628577.png)

新增的这个 B-Tree 索引你看着就眼熟了，这跟 InnoDB 的 b+ 树索引组织形式类似。

可以看一下这下面这两个语句的输出：

![image](https://mail.wangkekai.cn/52DC11D0-A087-477F-846C-9DB19FF0DEFA.png)

可以看到，执行 select * from t1 where id<5 的时候，优化器会选择 B-Tree 索引，所以返回结果是 0 到 4。 使用 force index 强行使用主键 id 这个索引，id=0 这一行就在结果集的最末尾了。  
一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。

为什么不建议在生产环境上使用内存表。这里的原因主要包括两个方面：

1. 锁粒度问题；
2. 数据持久化问题。

### 小 tips

1. 字符串 & 整形类型索引
    1. 当我们使用的字段是数值类型时，加引号或者不加引号(sql中单引号和双引号实现相同效果)都不影响索引的使用
    2. 当我们的字段是字符串类型时，不加引号的查询无法使用索引，加引号的查询才可正常使用索引
